---
layout: page
title: CV Cognition
description: Cross-cultural perceptual differences in vision understanding models
img: assets/img/cv_cognition.png
importance: 40
category: research
---

| Work performed at the Allen School -- from February 2023 to the present. Mentored by Sebastin Santy. PIs: Ranjay Krishna, Amy Zhang. |

<br>

Computer vision often treats perception as objective, and this assumption gets reflected in the way that datasets are collected and models are trained. For instance, image descriptions in different languages are typically assumed to be translations of the same semantic content. However, work in cross-cultural psychology and linguistics has shown that individuals differ in their visual perception depending on their cultural background and the language they speak. In this paper, we demonstrate significant differences in semantic content across languages in both dataset and model-produced captions. When data is multilingual as opposed to monolingual, captions have higher semantic coverage on average, as measured by scene graph, embedding, and linguistic complexity. For example, multilingual captions have on average 21.8% more objects, 24.5% more relations, and 27.1% more attributes than a set of monolingual captions. Moreover, models trained on content from different languages perform best against test data from those languages, while those trained on multilingual content perform consistently well across all evaluation data compositions. Our research provides implications for how diverse modes of perception can improve image understanding.

[arXiv preprint](https://arxiv.org/abs/2310.14356){:target="_blank" :btn }

<iframe src="https://arxiv.org/pdf/2310.14356.pdf" width="100%" height="400" style="border:1px solid black;"></iframe>






