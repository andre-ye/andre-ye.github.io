---
layout: page
title: agenda
permalink: /agenda/
description: My research agenda and ideas that excite me
nav: true
nav_order: 4
---

---

### ongoing projects
projects I am leading or co-leading

**Discursive Datasets.** with Amy Zhang (U. of Wa.) and Ranjay Krishna (U. of Wa.).
- Mary Gates Scholarship [Application](\assets\pdf\mary-gates-essay-discursive-datasets.pdf){:target="_blank"} (Winter 2024).

**Political Autonomy on Social Platforms.** with Katie Yurechko (Wash. & Lee, Oxford).
We set forth a framework for understanding and analyzing the pre-/political experience and autonomy of users in social platforms.

**Research Agenda for "Social Metaphysics.** with Mark Pock (U. of Wa.) and Jared Moore (Stanford).
More coming.

<!-- **Historicizing Morality for Language Models.** with Mark Pock (U. of Wa.) and Jared Moore (Stanford).
Taking the geneological method from Nietzsche and Foucault, we further develop the critique in [Talat et al. 2022](https://aclanthology.org/2022.naacl-main.56.pdf){:target="_blank"} through an analysis of moral development and contradiction, and propose alternative approaches for 'modeling morality'.
See: *sources forthcoming.*

**Non-Agential Theory of Meaning.** with Mark Pock (U. of Wa.) and Jared Moore (Stanford).
Many analytic theories of meaning and language require agential constructs such as intentionality or belief, whether implicitly or explicitly.
Borrowing from structuralist and post-structuralist work, we set forth a non-agential theory of meaning, with an application towards Large Language Models.
See: *sources forthcoming.* -->

---

### ongoing collaborations
projects I'm happy to be a small part of!

None at the moment. Soon to change...

<!-- **Limits of Value Pluralism in Alignment.** Taylor Sorenson (U. of Wa.), Liwei Jiang (U. of Wa.), et al. -->

---

### exciting ideas and directions
Kernels of research ideas I'm excited about.
If any of these excite you too, please shoot me an email at `andreye [at] uw [dot] edu`!


<!-- - *Breathing Datasets.* I previously briefly developed the notion of [economy of the dataset](https://andre-ye.github.io/writing/files/economy-of-the-dataset.pdf){:target="_blank"}, which deploys the Marxist notion of commodity fetishism and alienation to understand the simultaneous isolation and tightness of large-scale datasets. In response: can we develop less alienated, more intertwined datasets? Can we exploit hyperlinks and connections? Can we build a dataset in which each annotation is not one thing one person said at one time, but a living, breathing discourse? -->
- An exploration of what "selfhood" means for AI -- what does it mean when models say "As an AI language model..."? What might it mean to negate the [sycophantic, servile, mirror-like nature](https://arxiv.org/pdf/2402.07350.pdf){:target="_blank"} many current language models have been aligned to?
- Critique of the quasi-utilitarian focus on "preferences" in alignment. Frankfurt School will be useful here. In the style of "Antagonistic AI" (Alice Cai et al.)
- Serious HCI-style study of the use of LLMs and VLMs for philosophers. 
- An application of the "male gaze" to vision models (see: Laura Mulvey, ["Visual Pleasure and Narrative Cinema"](https://www.amherst.edu/system/files/media/1021/Laura%2520Mulvey,%2520Visual%2520Pleasure.pdf){:target="_blank"})
- Something like [Borges and AI](https://arxiv.org/pdf/2310.01425.pdf){:target="_blank"}, but with Dostoevsky (*Crime and Punishment*) or David Foster Wallace (*Infinite Jest*), possibly also Baudrillard (*Simulacra and Simulation*)
- Developing Vil√©m Flusser's notion of technical images for computer vision. See: [Into the Universe of Technical Images](https://www.are.na/block/3080997){:target="_blank"}.
- Investigating if computer vision (and/or language modeling) is guilty of what Donna Haraway calls the 'god trick', and building information systems which reflect Haraway's maxim that objectivity is partial perspective. See: [Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective](){:target="_blank"} and [A Cyborg Manifesto](){:target="_blank"}. ["Situated Cameras, Situated Knowledges"](https://arxiv.org/pdf/2307.00064.pdf){:target="_blank"} is a great start.
- What happens if we take Iris Murdoch's notion of 'moral vision' literally? Murdoch says that "moral differences are differences in vision" -- what we need is not a "renewed attempt to specify the facts but rather a fresh vision". What does this mean for computer vision? See: [The Sovereignty of Good](){:target="_blank"}, [Metaphysics as a Guide to Morals](){:target="_blank"}, and [Vision and Choice in Morality](){:target="_blank"}.


