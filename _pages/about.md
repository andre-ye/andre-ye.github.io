---
layout: about
title: about
permalink: /
# subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: pfp.jpg
  image_circular: false # crops the image to make it circular
  # address: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
latest_posts: true  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page 
---

<!-- I am currently relocating my personal website. You can view my original website [here](https://andre-ye.github.io/andre-ye.github.io-retired/){:target="_blank"} while I am transferring. -->

I am an undergraduate at the University of Washington studying philosophy and computer science. My interest is in the philosophy of technology and AI -- specifically political/ethical, ontological, and cultural dimensions. Some questions which excite me are:
Does AI stand for (epistemic, political, ethical) universality?
What are complications with value pluralism and other analytic ethical frameworks for AI?
Can we develop an ontology of datasets, models, and information flow? -- and what does this mean for ethical questions of consent, privacy, and property in human-AI interactions?
as well as the metaphysics of information, data, and language?

Previously, I have worked with
$$\{$$ [Ranjay Krishna](https://ranjaykrishna.com/index.html){:target="_blank"}, 
[Amy Zhang](https://homes.cs.washington.edu/~axz/){:target="_blank"}, 
[Sebastin Santy](https://sebastinsanty.com/){:target="_blank"} $$\}$$
on cross-cultural [perceptual differences](/projects/cv_cognition/){:target="_blank"} in vision understanding models;
$$\{$$[Jared Moore](https://jaredmoore.org/){:target="_blank"}
and Mark Pock$$\}$$ on social intentionality in LLMs;
the [Social Futures Lab](https://social.cs.washington.edu/){:target="_blank"}
on [uncertainty representation](/projects/confidence_contours/){:target="_blank"} in segmentation models;
the [Najafian Lab](https://dlmp.uw.edu/research-labs/najafian/najafian-lab-members){:target="_blank"}
on the [segmentation](/projects/foot_process_seg/){:target="_blank"} of kidney structures.
I have written a few [essays](/writing/philosophy){:target="_blank"} in philosophy, [two](/writing/mdldna){:target="_blank"} [books](/writing/mdl4td){:target="_blank"} on deep learning, a little bit of [fiction](/writing/fiction){:target="_blank"}, and many [data science articles](https://andre-ye.medium.com/){:target="_blank"}. 

Outside of academics, I enjoy listening to [lectures](https://www.youtube.com/watch?v=06KiOj6gjbs){:target="_blank"} by Slavoj Zizek (my favorite undead philosopher), playing piano, learning Russian and French, and thinking about swimming in the eternally incomplete UW pool. I'm always up for a chat, so feel free to reach out.

<center>
<img src="\assets\img\ghost-portraits.png" width="100%" />
</center>

<small>
  Composite image of The Disintegration of the Persistence of Memory (Dali), Edward Bellamy (GAN), Guernica (Picasso), still from Battleship Potemkin (Eisenstein), Relativity (Escher).
</small>

**Philosophy Interest Statement.** Aphorism 127 in Adorno’s *Minima Moralia* declares, “Intelligence is a moral category.” Every rational and intellectual endeavor expresses an ethical orientation. One usually takes from this that we need a meditation on the ethical waste and peril of human intellectual histories. But intelligence is no longer obviously an anthropocentric feature. My academic interest is in subjecting non-human intelligences (“AI”) to this very sort of meditation. Is the only ethical significance of AI the one that humans imbue into it? Might AI’s persistent exteriority to “HI” (Human Intelligence) better capture truths which themselves elude the rational (human) ego? Can AI ‘do’ philosophy, and does it represent a break in the history of philosophy?

<br>

<hr>

<br>

<center>
<a href="https://info.flagcounter.com/42Y6"><img src="https://s11.flagcounter.com/count2/42Y6/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
</center>

<br>

<hr>

<br>