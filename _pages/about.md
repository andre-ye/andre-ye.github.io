---
layout: about
title: about
permalink: /
# subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: pfp.jpg
  image_circular: false # crops the image to make it circular
  # address: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
latest_posts: true  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page 
---

<!-- I am currently relocating my personal website. You can view my original website [here](https://andre-ye.github.io/andre-ye.github.io-retired/){:target="_blank"} while I am transferring. -->

I am an undergraduate at the University of Washington studying philosophy and computer science. My interest is in the philosophy of technology and AI -- specifically political/ethical, ontological, and cultural dimensions. Some questions which excite me are:
How to  models reflect and distort cultural differences among humans?
Does AI stand for universality, and what ethical and political difficulties arise?
What are complications with value pluralism in AI?

Currently, I am working with Prof. Ranjay Krishna, Prof. Amy Zhang, and PhD student Sebastin Santy on cross-cultural perceptual differences in vision understanding models. 
Previously, I worked in the Social Futures Lab on uncertainty representation in segmentation models, the Najafian Lab on the segmentation of kidney structures, and Deepgram on curriculum learning in large transcription models.
I have written a few essays in philosophy, two books on deep learning, a little bit of fiction, and many data science articles. 

Outside of academics, I enjoy listening to lectures by Slavoj Zizek (my favorite undead philosopher), playing piano, learning Russian and French, and thinking about swimming in the eternally incomplete UW pool. I'm always up for a chat, so feel free to reach out.