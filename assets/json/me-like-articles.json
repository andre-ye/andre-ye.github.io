{
    "categories": [
        {
            "title": "Position Papers",
            "description": "These papers make really interesting arguments about human-AI interaction which I find compelling or at least useful to think about. (I don't necessarily agree with all the papers below.)",
            "papers": [
                {
                    "title": "We Can't Understand AI Using our Existing Vocabulary",
                    "authors": "John Hewitt, Robert Geirhos, Been Kim",
                    "year": 2025,
                    "commentary": "A compelling articulation of what human-AI communication could look like. Proposes neologism learning.",
                    "link": "https://openreview.net/pdf?id=asQJx56NqB"
                },
                {
                    "title": "Prompting as Scientific Inquiry",
                    "authors": "Ari Holtzman, Chenhao Tan",
                    "year": 2025,
                    "commentary": "Makes a really interesting case for disambiguating prompt 'engineering' from a possible 'prompt science'. The writing is very compelling. A helpful analogy presented in the paper is the idea that plant breeders were able to infer a lot of the internal structure of plants before genetic theory explained it. Not sure where I stand on this still but it's given me a lot to think about, especially w.r.t. 'aesthetic' concerns in ML research that bar 'prompting' from being seen as a legitimate research method. I do agree with the paper's claim that many important works in NLP are basically interfaces/structures upon prompting, and we shouldn't be afraid to more closely associate them with a 'prompt science'.",
                    "link": "https://arxiv.org/abs/2507.00163"
                },
                {
                    "title": "AI Should Not Be An Imitation Game: Centaur Evaluations",
                    "authors": "Andreas Haupt, Erik Brynjolfsson",
                    "year": 2025,
                    "commentary": "Advocates and proposes directions for systematic AI evalutions involving real human interaction.",
                    "link": "https://openreview.net/pdf?id=LkdH35003E"
                },
                {
                    "title": "AI Technologies are System Maps, and You are a Cartographer",
                    "authors": "Nicholas Vincent",
                    "year": 2023,
                    "commentary": "Explains the 'data as labor' perspective for AI via the compelling analogy of map economics.",
                    "link": "https://dataleverage.substack.com/p/ai-technologies-are-system-maps-and-you-are-a-cartographer"
                },
                {
                    "title": "Toward cultural interpretability: A linguistic anthropological framework for describing and evaluating large language models",
                    "authors": "Graham M Jones, Shai Satran, Arvind Satyanarayan",
                    "year": 2025,
                    "commentary": "Advocates for understanding LLM behavior as indicative of nuances in human social behavior.",
                    "link": "https://vis.csail.mit.edu/pubs/cultural-interpretability.pdf"
                },
                {
                    "title": "HCI for AGI",
                    "authors": "Meredith Ringel Morris",
                    "year": 2025,
                    "commentary": "Useful outline of what HCI researchers can contribute to 'AGI'. It's not obvious (and people may fear that) interaction problems will be solved by AGI. Perhaps not?",
                    "link": "https://dl.acm.org/doi/10.1145/3708815"
                },
                {
                    "title": "AI and the Demise of College Writing",
                    "authors": "Adam Walker",
                    "year": 2025,
                    "commentary": "Advocates for rhetoric over composition as the methodology for writing pedagogy in the AI era.",
                    "link": "https://www.youtube.com/watch?v=_PPx4KV8SaQ"
                },
                 {
                    "title": "Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions",
                    "authors": "Hua Shen, Tiffany Knearem, Reshmi Ghosh, Kenan Alkiek, Kundan Krishna, et al.",
                    "year": 2024,
                    "commentary": "A recognition that not only must AI 'align to' human (values, behavior, knowledge, etc.) (-- whatever this means), but we also need to think about how humans might 'align' to AI by working with AI-structured systems. This paper recognizes social 'looping effects' brought about by AI and its behavior.",
                    "link": "https://arxiv.org/abs/2406.09264"
                },
                {
                    "title": "Large AI models are cultural and social technologies",
                    "authors": "Henry Farrell, Alison Gopnik, Cosma Shalizi, James Evans",
                    "year": 2025,
                    "commentary": "Argues for understanding LLMs as technologies that reconstitute human knowledge in efficient and widely distributed ways, in a lineage of other such instruments, including markets and communication media.",
                    "link": "https://henryfarrell.net/wp-content/uploads/2025/03/Science-Accepted-Version.pdf"
                },
                {
                    "title": "Political Neutrality in AI Is Impossible- But Here Is How to Approximate It",
                    "authors": "Jillian Fisher, Ruth E. Appel, Chan Young Park, Yujin Potter, Liwei Jiang, et al.",
                    "year": 2025,
                    "commentary": "Makes what I think is an important point that there is no such thing as 'eliminating bias' in AI, and gives reasonable measures for how to proceed nevertheless in not building partisan hack LLMs. I personally find the 'Output Transparency', 'System Transaprency', and 'Neutrality Through Diversity' approximation techniques the most compelling. I appreciate what this paper does for broadening a notion of 'neutrality' in AI, drawing on the large existing body of political and philosophical work making the point.",
                    "link": "https://arxiv.org/abs/2503.05728"
                }
            ]
        },

        {
            "title": "AI Tools for Human Knowledge",
            "description": "These tools leverage the properties of AI to help us know more.",
            "papers": [
                {
                    "title": "Sparse Autoencoders for Hypothesis Generation",
                    "authors": "Rajiv Movva, Kenny Peng, Nikhil Garg, Jon Kleinberg, Emma Pierson",
                    "year": 2025,
                    "commentary": "This paper uses sparse autoencoder features to identify possible hypotheses to explain relationships between text and a dependent variable.",
                    "link": "https://arxiv.org/abs/2502.04382"
                },
                {
                    "title": "Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM",
                    "authors": "Michelle S. Lam, Janice Teoh, James Landay, Jeffrey Heer, Michael S. Bernstein",
                    "year": 2024,
                    "commentary": "This paper defines LLM operations for extracting concepts from large amounts of unstructured text, useful for social sciences inquiry.",
                    "link": "https://arxiv.org/abs/2404.12259"
                },
                {
                    "title": "Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in AlphaZero",
                    "authors": "Lisa Schut, Nenad Tomasev, Tom McGrath, Demis Hassabis, Ulrich Paquet, Been Kim",
                    "year": 2023,
                    "commentary": "The authors show how machine-unique/discovered chess-playing concepts can be extracted and taught to human chess-players.",
                    "link": "https://arxiv.org/abs/2310.16410"
                }
            ]
        },

        {
            "title": "Concept-structured AI",
            "description": "These approaches systematically build human-level concepts into the way AI models are designed, so we can understand and intervene.",
            "papers": [
                {
                    "title": "Jury Learning: Integrating Dissenting Voices into Machine Learning Models",
                    "authors": "Mitchell L. Gordon, Michelle S. Lam, Joon Sung Park, Kayur Patel, Jeffrey T. Hancock, Tatsunori Hashimoto, Michael S. Bernstein",
                    "year": 2022,
                    "commentary": "By modeling individual views rather than an aggregated 'view', we can explicitly define the voices 'heard' in making a decision and consider counterfactuals.",
                    "link": "https://arxiv.org/abs/2202.02950"
                },
                {
                    "title": "Concept Bottleneck Models",
                    "authors": "Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, Percy Liang",
                    "year": 2020,
                    "commentary": "By learning explicitly defined concepts to bridge independent and dependent variables, we can better interpret model decisions and intervene on mistakes.",
                    "link": "https://arxiv.org/abs/2007.04612"
                },
                {
                    "title": "Explaining Datasets in Words: Statistical Models with Natural Language Parameters",
                    "authors": "Ruiqi Zhong, Heng Wang, Dan Klein, Jacob Steinhardt",
                    "year": 2024,
                    "commentary": "Language modeling in terms of natural language predicates",
                    "link": "https://arxiv.org/abs/2409.08466"
                },
                {
                    "title": "Large Concept Models: Language Modeling in a Sentence Representation Space",
                    "authors": "Lo√Øc Barrault, Paul-Ambroise Duquenne, Maha Elbayad, Artyom Kozhevnikov, Belen Alastruey, et al.",
                    "year": 2024,
                    "commentary": "Language modeling operating in embedding rather than token space.",
                    "link": "https://arxiv.org/abs/2412.08821"
                },
                {
                    "title": "Backpack Language Models",
                    "authors": "John Hewitt, John Thickstun, Christopher D. Manning, Percy Liang",
                    "year": 2023,
                    "commentary": "By creating an LM architecture in which input tokens have a direct log-linear effect on the output, we can intervene precisely on the model output.",
                    "link": "https://arxiv.org/abs/2305.16765"
                }
            ]
        },


        {
            "title": "Interpretability",
            "description": "Interesting works on understanding how complex models produce outputs and represent knowledge.",
            "papers": [
                {
                    "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing",
                    "authors": "Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, Dimitris Bertsimas",
                    "year": 2023,
                    "commentary": "By probing with sparsity constraints, we can identify not only if model activations represent some feature but whether specific neurons encode certain features.",
                    "link": "https://arxiv.org/abs/2305.01610"
                },
                {
                    "title": "Discovering Latent Knowledge in Language Models Without Supervision",
                    "authors": "Collin Burns, Haotian Ye, Dan Klein, Jacob Steinhardt",
                    "year": 2024,
                    "commentary": "A method to probe structure in language models without any notion of ground truth, relying instead on the consistency property of tru statements.",
                    "link": "https://arxiv.org/abs/2212.03827"
                },
                {
                    "title": "Language Models Use Trigonometry to Do Addition",
                    "authors": "Subhash Kantamneni, Max Tegmark",
                    "year": 2025,
                    "commentary": "The title is all you need to know! Super cool!",
                    "link": "https://arxiv.org/abs/2502.00873"
                }
            ]
        },


        {
            "title": "Human-AI Interaction",
            "description": "Interesting HCI-oriented work exploring how we can interact with AI or with other humans mediated by AI.",
            "papers": [
                {
                    "title": "Embedding Comparator: Visualizing Differences in Global Structure and Local Neighborhoods via Small Multiples",
                    "authors": "Angie Boggust, Brandon Carter, Arvind Satyanarayan",
                    "year": 2022,
                    "commentary": "A very useful interface for comparing differences in embeddings with interesting applications to model training development and the social sciences.",
                    "link": "https://arxiv.org/abs/1912.04853"
                }
            ]
        },

        {
            "title": "Philosophy",
            "description": "Smaller articles in contemporary-ish philosophy that I think are interesting or insightful.",
            "papers": [
                {
                    "title": "Why Isn‚Äôt There More Progress in Philosophy?",
                    "authors": "David J. Chalmers",
                    "year": 2011,
                    "commentary": "Asks an interesting question and gives some helpful directions to start thinking about what progress means in philosophy and how 'premise deniability' might be a relevant factor.",
                    "link": "https://consc.net/papers/progress.pdf"
                }
            ]
        },
        

        {
            "title": "Miscellaneous",
            "description": "Interesting HCI-oriented work exploring how we can interact with AI or with other humans mediated by AI.",
            "papers": [
                {
                    "title": "The Economics of Maps",
                    "authors": "Abhishek Nagaraj, Scott Stern",
                    "year": 2020,
                    "commentary": "An interesting analysis of economic issues in who uses and produces maps.",
                    "link": "https://www.aeaweb.org/articles?id=10.1257/jep.34.1.196"
                }
            ]
        }
    ]
}